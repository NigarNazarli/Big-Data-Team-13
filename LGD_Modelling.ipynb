{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f13327e1-ff54-46ca-8164-d1400c9183d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java: /Library/Java/JavaVirtualMachines/zulu-8.jdk/Contents/Home\n",
      "Spark: /opt/spark\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/Library/Java/JavaVirtualMachines/zulu-8.jdk/Contents/Home\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark\"\n",
    "\n",
    "# Remove wrong pyspark (Anaconda)\n",
    "sys.path = [p for p in sys.path if \"site-packages/pyspark\" not in p]\n",
    "\n",
    "# Add correct Spark PySpark\n",
    "sys.path.insert(0, \"/opt/spark/python\")\n",
    "sys.path.insert(1, \"/opt/spark/python/lib/py4j-0.10.9.7-src.zip\")\n",
    "\n",
    "os.environ[\"PATH\"] = (\n",
    "    os.environ[\"JAVA_HOME\"] + \"/bin:\" +\n",
    "    os.environ[\"SPARK_HOME\"] + \"/bin:\" +\n",
    "    os.environ[\"PATH\"]\n",
    ")\n",
    "\n",
    "print(\"Java:\", os.environ[\"JAVA_HOME\"])\n",
    "print(\"Spark:\", os.environ[\"SPARK_HOME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40da88c7-d784-4e6d-b069-3ed6a7ddc52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/02 13:43:07 WARN Utils: Your hostname, apple-MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 10.0.12.191 instead (on interface en0)\n",
      "25/12/02 13:43:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/02 13:43:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.12.191:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>LGD Prediction</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x104f51290>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LGD Prediction\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9700fda-bfe1-4c92-867f-2c04ae082c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.hadoop.fs.defaultFS\", \"file:///\")\n",
    "spark.conf.set(\"spark.hadoop.fs.file.impl\", \"org.apache.hadoop.fs.LocalFileSystem\")\n",
    "spark.conf.set(\"spark.hadoop.fs.hdfs.impl\", \"org.apache.hadoop.hdfs.DistributedFileSystem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eebff24-32a3-4a8e-976b-99e9300ad604",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\n",
    "    \"file:///Users/apple/Desktop/lgd_data.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\";\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6550eecf-84b8-4c23-a9a7-a361c40e5bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, col\n",
    "\n",
    "# columns that must be numeric\n",
    "to_fix = [\n",
    "    \"Interest Rate (%)\",\n",
    "    \"Income ($)\",\n",
    "    \"Loan to Value Ratio (%)\",\n",
    "    \"Debt to Income Ratio (%)\",\n",
    "    \"LGD%\"\n",
    "]\n",
    "\n",
    "for c in to_fix:\n",
    "    data = data.withColumn(c, regexp_replace(col(c), \",\", \".\"))\n",
    "    data = data.withColumn(c, col(c).cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b1932b-a266-451b-b055-52844a49c55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    \"Exposure Amount ($)\", \"Credit Score\", \"Loan Term (Months)\",\n",
    "    \"Employment History (Years)\", \"Previous Defaults\"\n",
    "]\n",
    "\n",
    "for c in numeric_cols:\n",
    "    data = data.withColumn(c, col(c).cast(\"double\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ced0c7f4-fe06-49fb-84f5-a405ec0fad23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+------------------+-----------------+----------+-----------------------+------------------------+--------------------------+-----------------+--------------+------------------+---------------+------+-----------+\n",
      "|Exposure Amount ($)|Credit Score|Loan Term (Months)|Interest Rate (%)|Income ($)|Loan to Value Ratio (%)|Debt to Income Ratio (%)|Employment History (Years)|Previous Defaults|Home Ownership|      Loan Purpose|      Loan Type|Region|       LGD%|\n",
      "+-------------------+------------+------------------+-----------------+----------+-----------------------+------------------------+--------------------------+-----------------+--------------+------------------+---------------+------+-----------+\n",
      "|           238203.0|       729.0|              36.0|             3.81|   47603.0|                   88.0|                    24.0|                       4.0|              2.0|          Rent|  Home Improvement|Adjustable Rate| South|0.009999874|\n",
      "|           170008.0|       745.0|              36.0|             6.68|   67474.0|                   71.0|                    43.0|                       4.0|              2.0|      Mortgage|         Auto Loan|Adjustable Rate| South|0.757182015|\n",
      "|           198937.0|       681.0|              24.0|             8.38|   77036.0|                   74.0|                    46.0|                       6.0|              1.0|           Own|     Personal Loan|     Fixed Rate|  West|0.575146906|\n",
      "|           262045.0|       684.0|              48.0|             5.45|   55083.0|                   85.0|                    24.0|                       0.0|              0.0|      Mortgage|     Home Purchase|Adjustable Rate|  West|0.009998283|\n",
      "|           243378.0|       758.0|              72.0|             6.64|   70148.0|                   78.0|                    40.0|                       5.0|              0.0|      Mortgage|Debt Consolidation|     Fixed Rate| North|        1.0|\n",
      "|           101136.0|       745.0|              48.0|             3.65|   59976.0|                   75.0|                    58.0|                       1.0|              0.0|      Mortgage|  Home Improvement|Adjustable Rate| North|0.310947635|\n",
      "|           197504.0|       713.0|              60.0|             6.37|   26494.0|                   77.0|                    32.0|                       3.0|              1.0|          Rent|     Personal Loan|Adjustable Rate|  West|0.025796946|\n",
      "|           142432.0|       706.0|              48.0|             2.22|   68838.0|                   89.0|                    33.0|                       4.0|              0.0|      Mortgage|     Personal Loan|Adjustable Rate| North|0.027030443|\n",
      "|           144839.0|       655.0|              48.0|             7.05|  110258.0|                   80.0|                    43.0|                       3.0|              2.0|      Mortgage|Debt Consolidation|     Fixed Rate|  West|0.873183328|\n",
      "|           170530.0|       679.0|              72.0|            10.13|   67740.0|                   62.0|                    45.0|                       4.0|              1.0|          Rent|     Home Purchase|     Fixed Rate| North|0.668732774|\n",
      "+-------------------+------------+------------------+-----------------+----------+-----------------------+------------------------+--------------------------+-----------------+--------------+------------------+---------------+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- Exposure Amount ($): double (nullable = true)\n",
      " |-- Credit Score: double (nullable = true)\n",
      " |-- Loan Term (Months): double (nullable = true)\n",
      " |-- Interest Rate (%): double (nullable = true)\n",
      " |-- Income ($): double (nullable = true)\n",
      " |-- Loan to Value Ratio (%): double (nullable = true)\n",
      " |-- Debt to Income Ratio (%): double (nullable = true)\n",
      " |-- Employment History (Years): double (nullable = true)\n",
      " |-- Previous Defaults: double (nullable = true)\n",
      " |-- Home Ownership: string (nullable = true)\n",
      " |-- Loan Purpose: string (nullable = true)\n",
      " |-- Loan Type: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- LGD%: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(10)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f016217-8f32-40d7-b9f1-728d80850df3",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad70b59-19a9-4f97-92f0-e47bc9d1ac11",
   "metadata": {},
   "source": [
    "### Mean defaults per credit score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f372682a-4cda-4305-add5-900f4f329f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "w_credit = Window.partitionBy(\"Credit Score\")\n",
    "\n",
    "data = data.withColumn(\n",
    "    \"Defaults_mean_by_Credit_Score\",\n",
    "    F.avg(\"Previous Defaults\").over(w_credit)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf177a5-ed75-4df1-9675-9098678036be",
   "metadata": {},
   "source": [
    "### Mean income per region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17b6e080-a2e1-4617-938a-4d623a7c0496",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_region = Window.partitionBy(\"Region\")\n",
    "\n",
    "data = data.withColumn(\n",
    "    \"Income_mean_by_Region\",\n",
    "    F.avg(\"Income ($)\").over(w_region)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51acd823-b3c1-49b2-86ef-1be8eba2b04b",
   "metadata": {},
   "source": [
    "## Select final modeling columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67ac1cdc-f3fb-4cb8-9a92-03d5a49a09fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.select(\n",
    "    \"Exposure Amount ($)\",\n",
    "    \"Credit Score\",\n",
    "    \"Loan Term (Months)\",\n",
    "    \"Interest Rate (%)\",\n",
    "    \"Income ($)\",\n",
    "    \"Loan to Value Ratio (%)\",\n",
    "    \"Debt to Income Ratio (%)\",\n",
    "    \"Employment History (Years)\",\n",
    "    \"Previous Defaults\",\n",
    "    \"Home Ownership\",\n",
    "    \"Loan Purpose\",\n",
    "    \"Loan Type\",\n",
    "    \"Region\",\n",
    "    \"Defaults_mean_by_Credit_Score\",\n",
    "    \"Income_mean_by_Region\",\n",
    "    \"LGD%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eeb464-b580-4c6b-bda0-a6a6abd63fbc",
   "metadata": {},
   "source": [
    "## Build Encoding + Assembler + Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8936a5c-bf78-4ba7-b943-e4dbbcde8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "\n",
    "cat_cols = [\"Home Ownership\", \"Loan Purpose\", \"Loan Type\", \"Region\"]\n",
    "\n",
    "num_cols = [\n",
    "    \"Exposure Amount ($)\", \"Credit Score\", \"Loan Term (Months)\", \"Interest Rate (%)\",\n",
    "    \"Income ($)\", \"Loan to Value Ratio (%)\", \"Debt to Income Ratio (%)\",\n",
    "    \"Employment History (Years)\", \"Previous Defaults\",\n",
    "    \"Defaults_mean_by_Credit_Score\", \"Income_mean_by_Region\"\n",
    "]\n",
    "\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=c, outputCol=c+\"_idx\", handleInvalid=\"keep\")\n",
    "    for c in cat_cols\n",
    "]\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[c+\"_idx\" for c in cat_cols],\n",
    "    outputCols=[c+\"_ohe\" for c in cat_cols]\n",
    ")\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=num_cols + [c+\"_ohe\" for c in cat_cols],\n",
    "    outputCol=\"features_raw\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features_raw\",\n",
    "    outputCol=\"features\",\n",
    "    withMean=True,\n",
    "    withStd=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1427880d-b93f-47ac-a917-d83ae49b471b",
   "metadata": {},
   "source": [
    "## Train/Test Split + Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ba2f5cf-4fce-44f3-8f94-f356b8da1386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/02 13:43:20 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/12/02 13:43:23 WARN Instrumentation: [2e90ea50] regParam is zero, which might cause numerical instability and overfitting.\n",
      "25/12/02 13:43:23 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/12/02 13:43:23 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "25/12/02 13:43:23 WARN Instrumentation: [2e90ea50] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "lr = LinearRegression(labelCol=\"LGD%\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + [encoder, assembler, scaler, lr])\n",
    "\n",
    "train, test = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bc6fad-a084-4a40-b234-49ab3e8b368e",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "708b263d-15ee-4c22-8021-ffa6c0395cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 0.11797694189400731\n",
      "Train RMSE: 0.14459267364310394\n",
      "Train R2: 0.8197527977336208\n",
      "Test MAE: 0.11768973682640281\n",
      "Test RMSE: 0.14407408344804618\n",
      "Test R2: 0.8242087204800287\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "pred_train = model.transform(train)\n",
    "pred_test = model.transform(test)\n",
    "\n",
    "eval_mae = RegressionEvaluator(labelCol=\"LGD%\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "eval_rmse = RegressionEvaluator(labelCol=\"LGD%\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "eval_r2 = RegressionEvaluator(labelCol=\"LGD%\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "print(\"Train MAE:\", eval_mae.evaluate(pred_train))\n",
    "print(\"Train RMSE:\", eval_rmse.evaluate(pred_train))\n",
    "print(\"Train R2:\", eval_r2.evaluate(pred_train))\n",
    "\n",
    "print(\"Test MAE:\", eval_mae.evaluate(pred_test))\n",
    "print(\"Test RMSE:\", eval_rmse.evaluate(pred_test))\n",
    "print(\"Test R2:\", eval_r2.evaluate(pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b21d80-cce0-4f9e-ae3e-75b2bf1f48e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5664545b-569e-4578-b537-0bf46dc75a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
